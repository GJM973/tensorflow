{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "* Sequence of operation applied to matrix of input data\n",
    "* These operation are usually collections of additions & multiplications\n",
    "* The important trick with neural networks is called 'backpropagation'. Back propagation is a procedure that allows us to update the model variables based on the learning rate and the output of the loss function. \n",
    "* Another important feature to take note of in neural networks is the non-linear activation function. Since most neural networks are just combinations of addition and multiplication operations, they will not be able to model non-linear datasets. To address this issue, we have used the non-linear activation functions in the neural networks. This will allow the neural network to adapt to most non-linear situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementaing Operational Gates\n",
    "<img src=\"https://www.safaribooksonline.com/library/view/tensorflow-machine-learning/9781786462169/graphics/B05480_06_01.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We start off by loading TensorFlow and creating a graph session:\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now, we declare our model variable, input data, and placeholder. \n",
    "#We make our input data equal to the value 5, so that the multiplication factor to get 50 will be 10 (that is, 5X10=50):\n",
    "\n",
    "\n",
    "a = tf.Variable(tf.constant(4.))\n",
    "x_val = 5.\n",
    "x_data = tf.placeholder(dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next we add the operation to our computational graph:\n",
    "\n",
    "multiplication = tf.multiply(a, x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We will declare the loss function as the L2 distance between the output and the desired target value of 50:\n",
    "\n",
    "loss = tf.square(tf.subtract(multiplication, 50.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we initialize our model variable and declare our optimizing algorithm as the standard gradient descent:\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.01)\n",
    "train_step = my_opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing a Multiplication Gate Output to 50.\n",
      "4.0\n",
      "7.0 * 5.0 = 35.0\n",
      "7.0\n",
      "8.5 * 5.0 = 42.5\n",
      "8.5\n",
      "9.25 * 5.0 = 46.25\n",
      "9.25\n",
      "9.625 * 5.0 = 48.125\n",
      "9.625\n",
      "9.8125 * 5.0 = 49.0625\n",
      "9.8125\n",
      "9.90625 * 5.0 = 49.5313\n",
      "9.90625\n",
      "9.95313 * 5.0 = 49.7656\n",
      "9.95313\n",
      "9.97656 * 5.0 = 49.8828\n",
      "9.97656\n",
      "9.98828 * 5.0 = 49.9414\n",
      "9.98828\n",
      "9.99414 * 5.0 = 49.9707\n"
     ]
    }
   ],
   "source": [
    "#We can now optimize our model output towards the desired value of 50. \n",
    "#We do this by continually feeding in the input value of 5 and back propagating the loss to update the model variable towards the value of 10:\n",
    "\n",
    "\n",
    "print('Optimizing a Multiplication Gate Output to 50.')\n",
    "for i in range(10):\n",
    "    a_val_old = sess.run(a)\n",
    "    print(a_val_old)\n",
    "    sess.run(train_step, feed_dict={x_data: x_val})\n",
    "    a_val = sess.run(a)\n",
    "    mult_output = sess.run(multiplication, feed_dict={x_data: x_val})\n",
    "    print(str(a_val) + ' * ' + str(x_val) + ' = ' + str(mult_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will do the same for f(x)= a.x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We will start in exactly same way as the preceding example, except now we'll initialize two model variables, a and b:\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize two model variables a,b\n",
    "a = tf.Variable(tf.constant(1.))\n",
    "b = tf.Variable(tf.constant(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val = 5.\n",
    "x_data = tf.placeholder(dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "two_gate = tf.add(tf.multiply(a,x_data),b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'sub'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-24c76bd0d561>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtwo_gate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'sub'"
     ]
    }
   ],
   "source": [
    "loss = tf.square(tf.sub(two_gate,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_opt = tf.train.GradientDescentOptimizer(0.01)\n",
    "train_step = my_opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now optimize the model variables to train the output towards the target value of 50:\n",
    "\n",
    "print('\\nOptimizing Two Gate Output to 50.')\n",
    "for i in range(10):\n",
    "    # Run the train step\n",
    "    sess.run(train_step, feed_dict={x_data: x_val})\n",
    "    # Get the a and b values\n",
    "    a_val, b_val = (sess.run(a), sess.run(b))\n",
    "    # Run the two-gate graph output\n",
    "    two_gate_output = sess.run(two_gate, feed_dict={x_data: x_val})\n",
    "    print(str(a_val) + ' * ' + str(x_val) + ' + ' + str(b_val) + ' = ' + str(two_gate_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with Gates and Activation Functions\n",
    "<img src=\"https://www.safaribooksonline.com/library/view/tensorflow-machine-learning/9781786462169/graphics/B05480_06_11.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create two layer neural network - one layer through sigmoid function & another layer reLU\n",
    "* Loss function will be governed by L2 distance from 0.75\n",
    "* We will randomly pull data from normal distribution\n",
    "* Optimize towards 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sess = tf.Session()\n",
    "tf.set_random_seed(5)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "a1 = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "b1 = tf.Variable(tf.random_uniform(shape=[1,1]))\n",
    "a2 = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "b2 = tf.Variable(tf.random_uniform(shape=[1,1]))\n",
    "x = np.random.normal(2, 0.1, 500)\n",
    "x_data = tf.placeholder(shape=[None, 1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start Graph Session\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "tf.set_random_seed(5)\n",
    "np.random.seed(42)\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "a1 = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "b1 = tf.Variable(tf.random_uniform(shape=[1,1]))\n",
    "a2 = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "b2 = tf.Variable(tf.random_uniform(shape=[1,1]))\n",
    "x = np.random.normal(2, 0.1, 500)\n",
    "x_data = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "sigmoid_activation = tf.sigmoid(tf.add(tf.matmul(x_data, a1), b1))\n",
    "\n",
    "relu_activation = tf.nn.relu(tf.add(tf.matmul(x_data, a2), b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare the loss function as the difference between\n",
    "# the output and a target value, 0.75.\n",
    "loss1 = tf.reduce_mean(tf.square(tf.subtract(sigmoid_activation, 0.75)))\n",
    "loss2 = tf.reduce_mean(tf.square(tf.subtract(relu_activation, 0.75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Declare optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.01)\n",
    "train_step_sigmoid = my_opt.minimize(loss1)\n",
    "train_step_relu = my_opt.minimize(loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run loop across gate\n",
    "print('\\nOptimizing Sigmoid AND Relu Output to 0.75')\n",
    "loss_vec_sigmoid = []\n",
    "loss_vec_relu = []\n",
    "for i in range(500):\n",
    "    rand_indices = np.random.choice(len(x), size=batch_size)\n",
    "    \n",
    "    x_vals = np.transpose([x[rand_indices]])\n",
    "    \n",
    "    sess.run(train_step_sigmoid, feed_dict={x_data: x_vals})\n",
    "    sess.run(train_step_relu, feed_dict={x_data: x_vals})\n",
    "    \n",
    "    loss_vec_sigmoid.append(sess.run(loss1, feed_dict={x_data: x_vals}))\n",
    "    loss_vec_relu.append(sess.run(loss2, feed_dict={x_data: x_vals}))    \n",
    "    \n",
    "    sigmoid_output = np.mean(sess.run(sigmoid_activation, feed_dict={x_data: x_vals}))\n",
    "    relu_output = np.mean(sess.run(relu_activation, feed_dict={x_data: x_vals}))\n",
    "    \n",
    "    if i%50==0:\n",
    "        print('sigmoid = ' + str(np.mean(sigmoid_output)) + ' relu = ' + str(np.mean(relu_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_vec_sigmoid, 'k-', label='Sigmoid Activation')\n",
    "plt.plot(loss_vec_relu, 'r--', label='Relu Activation')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.title('Loss per Generation')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Implementing a One-Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x_vals = np.array([x[0:3] for x in iris.data])\n",
    "y_vals = np.array([x[3] for x in iris.data])\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2,  0.2,  0.2,  0.2,  0.2,  0.4,  0.3,  0.2,  0.2,  0.1,  0.2,\n",
       "        0.2,  0.1,  0.1,  0.2,  0.4,  0.4,  0.3,  0.3,  0.3,  0.2,  0.4,\n",
       "        0.2,  0.5,  0.2,  0.2,  0.4,  0.2,  0.2,  0.2,  0.2,  0.4,  0.1,\n",
       "        0.2,  0.1,  0.2,  0.2,  0.1,  0.2,  0.2,  0.3,  0.3,  0.2,  0.6,\n",
       "        0.4,  0.3,  0.2,  0.2,  0.2,  0.2,  1.4,  1.5,  1.5,  1.3,  1.5,\n",
       "        1.3,  1.6,  1. ,  1.3,  1.4,  1. ,  1.5,  1. ,  1.4,  1.3,  1.4,\n",
       "        1.5,  1. ,  1.5,  1.1,  1.8,  1.3,  1.5,  1.2,  1.3,  1.4,  1.4,\n",
       "        1.7,  1.5,  1. ,  1.1,  1. ,  1.2,  1.6,  1.5,  1.6,  1.5,  1.3,\n",
       "        1.3,  1.3,  1.2,  1.4,  1.2,  1. ,  1.3,  1.2,  1.3,  1.3,  1.1,\n",
       "        1.3,  2.5,  1.9,  2.1,  1.8,  2.2,  2.1,  1.7,  1.8,  1.8,  2.5,\n",
       "        2. ,  1.9,  2.1,  2. ,  2.4,  2.3,  1.8,  2.2,  2.3,  1.5,  2.3,\n",
       "        2. ,  2. ,  1.8,  2.1,  1.8,  1.8,  1.8,  2.1,  1.6,  1.9,  2. ,\n",
       "        2.2,  1.5,  1.4,  2.3,  2.4,  1.8,  1.8,  2.1,  2.4,  2.3,  1.9,\n",
       "        2.3,  2.5,  2.3,  1.9,  2. ,  2.3,  1.8])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 2\n",
    "tf.set_random_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)\n",
    "\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]\n",
    "\n",
    "#Converting data in range of 0 - 1\n",
    "def normalize_cols(m):\n",
    "    col_max = m.max(axis=0)\n",
    "    col_min = m.min(axis=0)\n",
    "    return (m-col_min) / (col_max - col_min)\n",
    "\n",
    "x_vals_train = np.nan_to_num(normalize_cols(x_vals_train))\n",
    "x_vals_test = np.nan_to_num(normalize_cols(x_vals_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "x_data = tf.placeholder(shape=[None, 3], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.safaribooksonline.com/library/view/tensorflow-machine-learning/9781786462169/graphics/B05480_06_04.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_layer_nodes = 5\n",
    "A1 = tf.Variable(tf.random_normal(shape=[3,hidden_layer_nodes]))\n",
    "b1 = tf.Variable(tf.random_normal(shape=[hidden_layer_nodes]))\n",
    "A2 = tf.Variable(tf.random_normal(shape=[hidden_layer_nodes,1]))\n",
    "b2 = tf.Variable(tf.random_normal(shape=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_output = tf.nn.relu(tf.add(tf.matmul(x_data, A1), b1))\n",
    "final_output = tf.nn.relu(tf.add(tf.matmul(hidden_output, A2),\n",
    "b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y_target - final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ZekeLabs\\Anaconda3-N\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "my_opt = tf.train.GradientDescentOptimizer(0.005)\n",
    "train_step = my_opt.minimize(loss)\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation: 50. Loss = 2.2276\n",
      "Generation: 100. Loss = 1.9738\n",
      "Generation: 150. Loss = 2.455\n",
      "Generation: 200. Loss = 2.1724\n",
      "Generation: 250. Loss = 1.9766\n",
      "Generation: 300. Loss = 2.7586\n",
      "Generation: 350. Loss = 1.7948\n",
      "Generation: 400. Loss = 1.5586\n",
      "Generation: 450. Loss = 2.1508\n",
      "Generation: 500. Loss = 2.0444\n"
     ]
    }
   ],
   "source": [
    "# First we initialize the loss vectors for storage.\n",
    "loss_vec = []\n",
    "test_loss = []\n",
    "for i in range(500):\n",
    "    # First we select a random set of indices for the batch.\n",
    "    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n",
    "    # We then select the training values\n",
    "    rand_x = x_vals_train[rand_index]\n",
    "    rand_y = np.transpose([y_vals_train[rand_index]])\n",
    "    # Now we run the training step\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    # We save the training loss\n",
    "    temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    loss_vec.append(np.sqrt(temp_loss))\n",
    "\n",
    "    # Finally, we run the test-set loss and save it.\n",
    "    test_temp_loss = sess.run(loss, feed_dict={x_data: x_vals_test, y_target: np.transpose([y_vals_test])})\n",
    "    test_loss.append(np.sqrt(test_temp_loss))\n",
    "    if (i+1)%50==0:\n",
    "        print('Generation: ' + str(i+1) + '. Loss = ' + str(temp_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wefR98B1j8HfgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x155b87fe7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_vec, 'k-', label='Train Loss')\n",
    "plt.plot(test_loss, 'r--', label='Test Loss')\n",
    "plt.title('Loss (MSE) per Generation')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.safaribooksonline.com/library/view/tensorflow-machine-learning/9781786462169/graphics/B05480_06_04.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Different Layers\n",
    "* There are more types of layers that are built-in functions inside TensorFlow. \n",
    "* The most popular layers that are used are convolutional layers and maxpool layers. \n",
    "* Create such layers with input data & with fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_size = 25\n",
    "data_1d = np.random.normal(size=data_size)\n",
    "x_input_1d = tf.placeholder(dtype=tf.float32, shape=[data_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Define function that will make a convolutional layer. \n",
    "* Define a random filter & create convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer_1d(input_1d, my_filter):\n",
    "    # Make 1d input into 4d [batch size, width, height, channels]\n",
    "    #Modify input data & output data to extend or collapse the extra dim needed\n",
    "    input_2d = tf.expand_dims(input_1d, 0)\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    # Perform convolution\n",
    "    convolution_output = tf.nn.conv2d(input_4d, filter=my_filter, strides=[1,1,1,1], padding=\"VALID\")\n",
    "    # Now drop extra dimensions\n",
    "    conv_output_1d = tf.squeeze(convolution_output)\n",
    "    return(conv_output_1d)\n",
    "\n",
    "my_filter = tf.Variable(tf.random_normal(shape=[1,5,1,1]))\n",
    "my_convolution_output = conv_layer_1d(x_input_1d, my_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_2d = tf.expand_dims(data_1d, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_3d = tf.expand_dims(input_2d, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ExpandDims_8:0' shape=(1, 1, 25, 1) dtype=float64>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(input_3d, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TensorFlow's activation functions will act element-wise by default\n",
    "def activation(input_1d):\n",
    "    return(tf.nn.relu(input_1d))\n",
    "my_activation_output = activation(my_convolution_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool(input_1d, width):\n",
    "    # First we make the 1d input into 4d.\n",
    "    input_2d = tf.expand_dims(input_1d, 0)\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    # Perform the max pool operation\n",
    "    pool_output = tf.nn.max_pool(input_4d, ksize=[1, 1, width, 1], strides=[1, 1, 1, 1], padding='VALID')\n",
    "    pool_output_1d = tf.squeeze(pool_output)\n",
    "    return(pool_output_1d)\n",
    "\n",
    "my_maxpool_output = max_pool(my_activation_output, width=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fully_connected(input_layer, num_outputs):\n",
    "    # Create weights\n",
    "    weight_shape = tf.squeeze(tf.pack([tf.shape(input_layer), [num_outputs]]))\n",
    "    weight = tf.random_normal(weight_shape, stddev=0.1)\n",
    "    bias = tf.random_normal(shape=[num_outputs])\n",
    "    # Make input into 2d\n",
    "    input_layer_2d = tf.expand_dims(input_layer, 0)\n",
    "    # Perform fully connected operations\n",
    "    full_output = tf.add(tf.matmul(input_layer_2d, weight), bias)\n",
    "    # Drop extra dimensions\n",
    "    full_output_1d = tf.squeeze(full_output)\n",
    "    return(full_output_1d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_full_output = fully_connected(my_maxpool_output, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-99-fe5b56445586>:1 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Input = array of length 25\n",
      "Convolution w/filter, length = 5, stride size = 1, results in an array of length 21:\n",
      "[  3.68702888e-01  -1.71500611e+00   1.12007046e+00  -3.17530465e+00\n",
      "   1.24583697e+00   1.10787702e+00   2.95928121e-03   3.04242730e+00\n",
      "  -1.09590828e+00   3.72558057e-01   2.00997210e+00  -1.03314447e+00\n",
      "   2.21650958e+00   1.91677201e+00   2.72375441e+00   1.53702784e+00\n",
      "  -1.78274453e-01   2.85260350e-01  -5.48149049e-01  -6.39494002e-01\n",
      "  -2.69923806e-01]\n",
      "\n",
      "Input = the above array of length 21\n",
      "ReLU element wise returns the array of length 21:\n",
      "[  3.68702888e-01   0.00000000e+00   1.12007046e+00   0.00000000e+00\n",
      "   1.24583697e+00   1.10787702e+00   2.95928121e-03   3.04242730e+00\n",
      "   0.00000000e+00   3.72558057e-01   2.00997210e+00   0.00000000e+00\n",
      "   2.21650958e+00   1.91677201e+00   2.72375441e+00   1.53702784e+00\n",
      "   0.00000000e+00   2.85260350e-01   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00]\n",
      "\n",
      "Input = the above array of length 21\n",
      "MaxPool, window length = 5, stride size = 1, results in the array of length 17:\n",
      "[ 1.24583697  1.24583697  1.24583697  3.0424273   3.0424273   3.0424273\n",
      "  3.0424273   3.0424273   2.21650958  2.21650958  2.72375441  2.72375441\n",
      "  2.72375441  2.72375441  2.72375441  1.53702784  0.28526035]\n",
      "\n",
      "Input = the above array of length 17\n",
      "Fully connected layer on all four rows with five outputs:\n",
      "[-1.2777679   0.15456843 -0.64093256  4.4379468   1.96764648]\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n",
    "feed_dict = {x_input_1d: data_1d}\n",
    "# Convolution Output\n",
    "print('Input = array of length 25')\n",
    "print('Convolution w/filter, length = 5, stride size = 1, results in an array of length 21:')\n",
    "print(sess.run(my_convolution_output, feed_dict=feed_dict))\n",
    "# Activation Output\n",
    "print('\\nInput = the above array of length 21')\n",
    "print('ReLU element wise returns the array of length 21:')\n",
    "print(sess.run(my_activation_output, feed_dict=feed_dict))\n",
    "# Maxpool Output\n",
    "print('\\nInput = the above array of length 21')\n",
    "print('MaxPool, window length = 5, stride size = 1, results in the array of length 17:')\n",
    "print(sess.run(my_maxpool_output, feed_dict=feed_dict))\n",
    "# Fully Connected Output\n",
    "print('\\nInput = the above array of length 17')\n",
    "print('Fully connected layer on all four rows with five outputs:')\n",
    "print(sess.run(my_full_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
